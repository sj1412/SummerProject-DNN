#In this regression example tinyML model using DNN, petal lenght of iris flower is predicted given sepal lenght, sepal width and petal width.
import numpy as np
import tensorflow as tf
from sklearn.datasets import load_iris
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
# Load Iris dataset
iris = load_iris()
X = iris.data[:, [0, 1, 3]]  # Input: Sepal length, sepal width, petal width
y = iris.data[:, 2]          
# Reshape y to be 2D (for regression)
y = y.reshape(-1, 1)
# Normalize input features
scaler_X = StandardScaler()
X_scaled = scaler_X.fit_transform(X)

# First split: Train and Test (80% train, 20% test)
X_temp, X_test, y_temp, y_test = train_test_split(
    X_scaled, y_scaled, test_size=0.2, random_state=42
)

# Second split: From 80% training, take 75% for training, 25% for validation
# This results in 60% train, 20% val, 20% test of total data
X_train, X_val, y_train, y_val = train_test_split(
    X_temp, y_temp, test_size=0.25, random_state=42
)
 #Build DNN model
model = tf.keras.Sequential([
    tf.keras.layers.Dense(16, activation='relu', input_shape=(3,)),  # Layer 1
    tf.keras.layers.Dense(12, activation='relu'),                    # Layer 2
    tf.keras.layers.Dense(4, activation='relu'),                     # Layer 3
    tf.keras.layers.Dense(1)                                         # Output layer (regression)
])
model.summary()
#compile model
model.compile(optimizer='adam', loss='mse')
model.fit(X_train, y_train, validation_data=(X_val, y_val), epochs=100, verbose=1)
# Evaluate model on test data
test_loss = model.evaluate(X_test, y_test, verbose=0)
print(f"Test MSE Loss: {test_loss:.4f}")

# Save original model
model.save("petallength-regression.keras")

# Convert to TFLite model
converter = tf.lite.TFLiteConverter.from_keras_model(model)
tflite_model = converter.convert()

# Save .tflite file
with open("iris_petal_length_regression.tflite", "wb") as f:
    f.write(tflite_model)
# Predict petal length on test set
pred = model.predict(X_test)
print(pred)

pred_actual = scaler_y.inverse_transform(pred)
print(pred_actual)

from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score
import numpy as np

# Inverse transform scaled values
y_test_actual = scaler_y.inverse_transform(y_test)

#Measuring performance of model
#Mean Squared Error (MSE)
mse = mean_squared_error(y_test_actual, pred_actual)

# Root Mean Squared Error (RMSE)
rmse = np.sqrt(mse)

# Mean Absolute Error (MAE)
mae = mean_absolute_error(y_test_actual, pred_actual)

# R-squared (Coefficient of Determination)
r2 = r2_score(y_test_actual, pred_actual)

# Print results
print(f"Mean Absolute Error (MAE): {mae:.4f} cm")
print(f"Root Mean Squared Error (RMSE): {rmse:.4f} cm")
print(f"RÂ² Score: {r2:.4f}")
